{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4820741e-c5f6-4fcf-9cac-06121c011fe2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861c6839-68c9-4bab-b2a3-910ca801c074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290b83ca-d3af-49dd-bac6-7b38565d0906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a function in Java that implements the f...</td>\n",
       "      <td>public int[] zeroMax(int[] nums)\\r\\n{\\r\\n    i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Write a function in Java that implements the f...   \n",
       "\n",
       "                                                Code  \n",
       "0  public int[] zeroMax(int[] nums)\\r\\n{\\r\\n    i...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "train_data = data[['prompt','Code']]\n",
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c840da28-c138-429f-9720-5f2c61b39ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Write a function in Java that implements the following logic: Return a version of the given array where each zero value in the array is replaced by the largest odd value to the right of the zero in the array. If there is no odd value to the right of the zero, leave the zero as a zero. Hint: in solving this: you may use a second helper function if you want, say to find the largest odd value to the right of a specified position.',\n",
       " 'public int[] zeroMax(int[] nums)\\r\\n{\\r\\n    int large;\\r\\n    for(int i = 0; i < nums.length - 1; i++)\\r\\n    {\\r\\n     if (nums[i] == 0)\\r\\n     {\\r\\n      \\tlarge = 0;\\r\\n        for(int j = i + 1; j < nums.length; j++)\\r\\n        {\\r\\n         \\t   if(nums[j] > large && nums[j] % 2 == 1)\\r\\n               {\\r\\n                \\tlarge = nums[j];   \\r\\n               }\\r\\n        \\r\\n            if (large != 0)\\r\\n            {\\r\\n             \\tnums[i] = max;   \\r\\n            }\\r\\n        }\\r\\n     }\\r\\n    }\\r\\n        return nums;\\r\\n}\\r\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.values.tolist()\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974d3986-4865-45e1-9cb3-a6eb15585c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f774631-0935-471c-a767-1e649f8da685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_num = int(0.8 * len(train_data))\n",
    "\n",
    "with open('train_data.jsonl', 'w') as f:\n",
    "    for d in train_data[:train_num]:\n",
    "        d = {\n",
    "            'context':'',\n",
    "            'question':d[0],\n",
    "            'answer':d[1]\n",
    "        }\n",
    "        f.write(json.dumps(d)+'\\n')\n",
    "        \n",
    "with open('val_data.jsonl', 'w') as f:\n",
    "    for d in train_data[train_num:]:\n",
    "        d = {\n",
    "            'context':'',\n",
    "            'question':d[0],\n",
    "            'answer':d[1]\n",
    "        }\n",
    "        f.write(json.dumps(d)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5dcb27-a4d7-4848-a74f-7f0744293c14",
   "metadata": {},
   "source": [
    "# fine-turning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ea8b9b-b5b8-4297-a30e-2ae8381dcca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM,\n",
    "                          TrainingArguments, Trainer, DataCollatorForSeq2Seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a18c7d7-1812-4250-8ae9-9e4182401308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147127ef88bc489ca97043e61b5e236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b072f722558460babef03e1a72a2f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载自己的数据集\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('json', data_files='train_data.jsonl', split='train')\n",
    "eval_dataset = load_dataset('json', data_files='val_data.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "914bc193-17ac-4d67-b261-e26d08660688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '',\n",
       " 'question': 'Write a function in Java that implements the following logic: Given a number n, return true if n is in the range 1..10, inclusive. Unless \"outsideMode\" is true, in which case return true if the number is less or equal to 1, or greater or equal to 10.',\n",
       " 'answer': 'public boolean in1To10(int n, boolean outsideMode)\\r\\n{\\r\\n    if (outsideMode)\\r\\n    {\\r\\n        if (n <=1 || n >=10)\\r\\n        {\\r\\n            return true;\\r\\n        }\\r\\n    }\\r\\n    else if (n>=1 || n<=10)\\r\\n    {\\r\\n        return true;\\r\\n    }\\r\\n}\\r\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17d3877a-5fdf-4b25-9358-f3828224f3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb6e93136ce4c8ca3f6558d83f97754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = 'CodeLlama-7b-Instruct-hf'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca1a26-f4d8-41a2-aa2b-badbee0da61d",
   "metadata": {},
   "source": [
    "# 不微调的时候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49fe8e3f-7069-4dbf-8b75-09dfdc79f20e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are programming coder.\n",
    "\n",
    "Now answer the question:\n",
    "\n",
    "{}\"\"\"\n",
    "prompts = [prompt.format(train_dataset[i]['question']) for i in [1,20,32,45,67]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b9ebf0f-0c16-40ac-b0d3-d89bca9202df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8e1d8c1-d2a1-434a-ad0d-8a2ecedfd956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You are programming coder.\\n\\nNow answer the question:\\n\\nGiven a string str, find all places where a three-letter combination starting with \"z\" and ending with \"p\" occurs. Return a string where for all such three-letter sequences, the middle letter has been removed. For example, a string like \"zipXzap\" would produce a result of \"zpXzp\".\\n\\nNote:\\n\\n* The input string will only contain lowercase letters.\\n* The input string will have a length of at most 1000.\\n\\nExample:\\n\\nInput: \"zazbzp\"\\nOutput: \"zbzp\"\\n\\nInput: \"zazbzpz\"\\nOutput: \"zbzpz\"\\n\\nInput: \"zazbzpzp\"\\nOutput: \"zbzpzp\"\\n\\nInput: \"zazbzpzpz\"\\nOutput: \"zbzpzpz\"\\n\\nInput: \"zazbzpzpzp\"\\nOutput: \"zbzpzpzp\"\\n\\nInput: \"zazbzpzpzpz\"\\nOutput: \"zbzpzpzpz\"\\n\\nInput: \"zazbzpzpzpzp\"\\nOutput: \"zbzpzpzpzp\"\\n\\nInput: \"zazbzpzpzpzpz\"\\nOutput: \"zbzpzpzpzpz\"\\n\\nInput: \"zazbzpzpzpzpzp\"\\nOutput: \"zbzpzpzpzpzp\"\\n\\nInput: \"zazbz', 'You are programming coder.\\n\\nNow answer the question:\\n\\nGiven an array of ints, return true if every 2 that appears in the array is next to another 2. Otherwise, return false.\\n\\n\\n### Examples\\n\\n```\\ntwos(\"12212\") → true\\ntwos(\"122122\") → false\\ntwos(\"2222\") → true\\n```\\n\\n### Input/Output Table\\n\\n| Input                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ', \"You are programming coder.\\n\\nNow answer the question:\\n\\nGiven an array, return an array that contains exactly the same numbers as the original array, but rearranged so that every 4 is immediately followed by a 5. Do not move the 4's, but every other number may move. The array contains the same number of 4's and 5's, and every 4 has a number after it that is not a 4. In this version, 5's may appear anywhere in the original array. (This is a slightly harder version of the fix34 problem.)\\n\\nExample:\\n\\n    Input: [4, 5, 4, 4, 5, 4, 5, 4, 5, 4, 5]\\n    Output: [4, 5, 4, 5, 4, 5, 4, 4, 5, 4, 5]\\n\\nNote:\\n\\n    The input array will have at least 4 and at most 1000 elements.\\n    The input array will have at least one 4 and at least one 5.\\n\\n\\n## From\\n\\n[LeetCode](https://leetcode.com/problems/fix-numbers-to-make-array-alternating-4-and-5)\\n\", 'You are programming coder.\\n\\nNow answer the question:\\n\\nA sandwich is two pieces of bread with something in between. Write a Java method that takes in a string str and returns the string that is between the first and last appearance of \"bread\" in str. Return the empty string \"\" if there are not two pieces of bread.\\n\\nFor example, if str is \"bread, meat, bread\", the method should return \"meat\".\\n\\nIf str is \"bread, meat, bread, bread\", the method should return \"meat, bread\".\\n\\nIf str is \"bread, bread\", the method should return \"\".\\n\\nIf str is \"bread, meat, bread, bread, meat\", the method should return \"meat, bread, meat\".\\n\\nIf str is \"bread, meat, bread, bread, meat, bread\", the method should return \"meat, bread, meat, bread\".\\n\\nIf str is \"bread, meat, bread, bread, meat, bread, bread\", the method should return \"meat, bread, meat, bread, bread\".\\n\\nIf str is \"bread, meat, bread, bread, meat, bread, bread, bread\", the method should return \"meat, bread, meat, bread, bread, bread\".\\n\\nIf str is \"bread, meat, bread, bread, meat, bread, bread, bread, bread\", the method should return \"meat, bread, meat, bread, bread, bread, bread\".\\n\\nIf str is \"bread, meat, bread, bread, meat, bread, bread, bread, bread, bread\", the method should return \"meat, bread, meat, bread, bread, bread, bread, bread\".', 'You are programming coder.\\n\\nNow answer the question:\\n\\nGiven an array of int values, return true if the group of n numbers at the start of the array is the same as the group of n numbers at the end of the array. For example, with {5, 6, 45, 99, 13, 5, 6}, the ends are the same for n == 0 and n == 2, and false for n == 1 and n == 3. You may assume that n is in the range 0..nums.length, inclusive.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**model_input, max_new_tokens=300)\n",
    "    outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38668e2f-1ebb-46d0-a6bc-2e9fedd23500",
   "metadata": {},
   "source": [
    "# lora fine-turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af7b50ac-a875-4d02-8699-07c0d30abca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51cc7958-72c7-4581-a72d-26a9bb49e65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "\n",
    "    # \"self-supervised learning\" means the labels are also the inputs:\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecc0e051-b429-43c4-bc83-5850f8e924a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt =f\"\"\"You are a powerful programming model. Your job is to answer questions about a database. You are given a question.\n",
    "\n",
    "You must output the code that answers the question.\n",
    "\n",
    "### Input:\n",
    "{data_point[\"question\"]}\n",
    "\n",
    "### Response:\n",
    "{data_point[\"answer\"]}\n",
    "\"\"\"\n",
    "    return tokenize(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67f750a-0f18-4c56-9d23-63a69146dffb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54ee821f0c44c10aa6245fef5ef90ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e544ce5c-c53d-4519-a481-5427a8a1e7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenized_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d252184b-19b1-40ca-987e-f467dfc07701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train() # put model back into training mode\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\",\n",
    "    \"o_proj\",\n",
    "],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21d34e21-ddfc-4e3b-af53-ec0c62b0dfe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ae54a85-4f4e-463c-9b63-8307b9d1fddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7c2ca5b-a77f-4165-8942-415a9d03c0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "per_device_train_batch_size = 32\n",
    "gradient_accumulation_steps = batch_size // per_device_train_batch_size\n",
    "output_dir = \"code-llama-ft\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        warmup_steps=100,\n",
    "        max_steps=400,\n",
    "        learning_rate=3e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_torch\",\n",
    "        evaluation_strategy=\"steps\", # if val_set_size > 0 else \"no\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_steps=20,\n",
    "        output_dir=output_dir,\n",
    "        load_best_model_at_end=False,\n",
    "        group_by_length=True, # group sequences of roughly the same length together to speed up training\n",
    "        report_to=\"none\", # if use_wandb else \"none\", wandb\n",
    "        run_name=f\"codellama-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\", # if use_wandb else None,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "870304c6-32d3-46e9-b7ba-037ec18d5b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling the model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 1:52:21, Epoch 123/134]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.294400</td>\n",
       "      <td>1.199093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.017600</td>\n",
       "      <td>0.828217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.358509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.245803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.223246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.241282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.257463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.304411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.385443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.403556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.443396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.475544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.509247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.508409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.534667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.534106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.539857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.550800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.548977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.559280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory code-llama-ft/checkpoint-20 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory code-llama-ft/checkpoint-40 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory code-llama-ft/checkpoint-60 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.21240129575133324, metrics={'train_runtime': 6758.7791, 'train_samples_per_second': 7.575, 'train_steps_per_second': 0.059, 'total_flos': 6.113905684481311e+17, 'train_loss': 0.21240129575133324, 'epoch': 123.08})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())).__get__(\n",
    "    model, type(model)\n",
    ")\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    print(\"compiling the model\")\n",
    "    model = torch.compile(model)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce1456-2d1c-42c3-9046-30f322765fe5",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ae143f-ae9d-4f22-b90a-64bcc197e273",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b58bb69d1a46ddaea6426797fb51a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "base_model = 'CodeLlama-7b-Instruct-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6790e8f2-8159-4184-b0aa-4613ae5ea7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "output_dir = \"code-llama-ft/checkpoint-100\"\n",
    "model = PeftModel.from_pretrained(model, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851f8b79-c37e-4ceb-bc6e-7700073526d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1406: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a powerful programming model. Your job is to answer questions about a database. You are given a question.\n",
      "\n",
      "You must output the code that answers the question.\n",
      "\n",
      "### Input:\n",
      "Write a function in Java that takes an array and returns the sum of the numbers in the array, or 0 if the array is empty. Except the number 13 is very unlucky, so it does not count any 13, or any number that immediately follows a 13.\n",
      "\n",
      "### Response:\n",
      "public int sum13(int[] nums)\n",
      "{\n",
      "    int sum = 0;\n",
      "    for (int i = 0; i < nums.length; i++)\n",
      "    {\n",
      "        if (nums[i] != 13)\n",
      "        {\n",
      "            sum = sum + nums[i];\n",
      "        }\n",
      "        else if (nums[i] == 13 && nums[i - 1] !=\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful programming model. Your job is to answer questions about a database. You are given a question.\n",
    "\n",
    "You must output the code that answers the question.\n",
    "\n",
    "### Input:\n",
    "Write a function in Java that takes an array and returns the sum of the numbers in the array, or 0 if the array is empty. Except the number 13 is very unlucky, so it does not count any 13, or any number that immediately follows a 13.\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**model_input, max_new_tokens=100)[0]\n",
    "    print(tokenizer.decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5ba00-afe0-446d-a563-5838d2d9de55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
